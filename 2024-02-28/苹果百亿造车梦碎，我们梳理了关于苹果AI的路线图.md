# 苹果百亿造车梦碎，我们梳理了关于苹果AI的路线图

# 苹果百亿造车梦碎，我们梳理了关于苹果AI的路线图

文/腾讯科技 郝博阳、郭晓静

苹果电动汽车项目，通常被称为“泰坦计划”（Project
Titan），于2014年启动，投入数十亿美金，"泰坦"（Titan）来源于希腊神话，与创造力和巨大神力相联系。这个被苹果内部给予厚望的“神之项目”，即将被叫停，而团队将部分转岗至生成式人工智能项目。

**“神力”被转移至生成式AI** ，这已经成为苹果日益重要的战略重心。转岗的团队即向John
Giannandrea汇报，他在2018年加入苹果公司，担任机器学习和人工智能战略高级副总裁。他在苹果的职责包括领导公司的AI团队，推动Siri和其他AI项目的改进和发展。

而在2023年的9月8日，外媒The Information首次曝光了苹果公司AI大模型开发团队的核心成员，其中就包括John
Giannandrea，还有参与创造Java的Arthur Van Hoff、神经网络领域专家Ruoming Pang，强强联手助力苹果AI大模型发展。

以上这些人员的调整及变动，外界都是通过媒体的爆料而得知。苹果这家引入注目的公司，在众多美国科技大厂争相高调宣布AI战略的时候，显得过分沉默，没有在任何官方发布会、甚至官方途径透露过他们的AI战略。

常年跟踪苹果的科技记者马克·古尔曼（Mark Gurman）在《Power
On》中透露，苹果计划在即将到来的全球开发者大会（WWDC）上推出一系列基于生成式人工智能的工具，这可能包括对Siri的改进。这些新工具预计将作为iOS
18的一部分，提供更自然的对话能力和更加个性化的用户体验。还有媒体猜测，苹果的基础大模型，也将于2024年的WWDC上正式推出。

这波生成式AI浪潮中，苹果真的慢了吗？我们将在本篇文章中，尝试梳理从2011年苹果推出语音助手Siri开始，对AI领域的持续投入。

一、AI弄潮儿Siri的没落之路

苹果在AI浪潮中曾经也是当之无愧的弄潮儿。

13年前，当Siri第一次亮相在iPhone
5发布会时，这个能流利对话的AI语音助手在当时的人眼中就等同于未来科技：它是当时人工智能最高的结晶。那时，连研究AI多年的苹果软件主管福斯托尔都不太相信这个产品能实现，他表示“我在人工智能领域工作了很长时间，但这仍然让我感到震惊。”。

**与GPT所依赖的深度学习完全不同，造就这一当时技术奇迹是NLP（自然语言理解），依靠一种硬编码的“命令和控制”系统来实现其对答的能力。**
它只能理解被编程进去的问题框架和请求，以及一堆分离的词语。如“查查北京今天的湿度”，“给老妈打个电话”。一旦要求超出编程体系，Siri马上无能为力。所以苹果有一个20人的团队，专门去想用户可能提什么问题，并把它们更新到系统里去。它的改进也极其繁复，在纽约时报采访其前项目负责人时，他表示，Siri的数据库非常庞大复杂，在这一体系进行任何简单更新，都需要重建整个数据库。并花上超过六周的时间。添加新的复杂的功能可能需要近一年的时间。这也是13年来，你的Siri虽然变聪明了点，但并不多的主要原因。

因为市场上确实缺乏能打的竞品，亚马逊的Alexa和谷歌的语音助手使用体验上并未拉开差距，苹果在这一能力的更新上也显得漫不经心，大公司病逐渐累积。**缺乏迭代让Siri甚至在苹果内部都遭自家员工厌恶。据Infornation报道，VisionPro的制造团队因为Siri表现太差曾一度想更换控制XR系统的语音助手。**

![](https://inews.gtimg.com/news_bt/O-ra5NWwP1uN8noYguzmk-
H_vcahTPUVMlrkrSpZdJZvQAA/1000)

在同一篇Information关于Siri乱局的报道中提到，在2018年苹果的新AI负责人John
Giannandrea从谷歌空降之前，Siri团队的内部状况是老员工争山头、技术路线摇摆不定、开发几乎停滞。Giannandrea成功整合了团队，也推动了Siri的演化速度。2019年，Siri收购的搜索团队Laserlike发布了第一项应用了Transformer架构的新Siri功能，可以让Siri整合网络信息来回答用户的问题。而谷歌已经至少提前五年开始应用这一技术了。

**虽然Siri开始动起来了，但它面前还面对着三座大山：官僚主义、顶层微操和设计团队的保守意见。**

官僚主义占据了大量的人力成本，比如腹死胎中的Siri
黑鸟计划，通过重写和简化Siri的架构，让它能更快反应，允许app开发人员创造功能，并能在iPhone端侧运行。结果为了满足高层老员工的10年Siri献礼工程的需求，人员都被抽调过去，最后只实现了iPhone端侧运行这一个功能。

另外一个大问题就是顶层对声誉的执着及无限向下的微操，它几乎阻止了所有大的技术创新。由于Siri的语音提示可能带来一定的公关风险，在2019年初，印第安纳州一名13岁男孩试图利用Siri查找校园枪击的方法之后，包括蒂姆·库克在内的苹果老板们经常给Siri挑错，这让他们很难有勇气尝试准确性不高的回答技术，比如深度学习技术。

而设计团队在苹果体系中的超然地位和严苛要求也让很多功能改变推行举步维艰，比如在发布新的搜索功能之前，工程师和设计团队就在回答的准确性问题上发生了冲突。例如，Siri设计团队希望该功能的答案接近完美，而工程团队则希望准确率接近80%。工程师们花了数月时间说服Siri设计师，并不是每一个答案都需要人工验证，这一限制将使Siri无法扩大规模来回答用户提出的大量问题。但直到一年以后，设计团队放弃了这一规定。加一个用户反馈疑惑，用于收集Siri缺陷的按钮都被设计团队否决了，原因是“他们希望Siri看起来全知全能”。

这一系列问题最终导致的结果之一是2022年底，在苹果AI体系中最有创新能力的Laserlike团队的三名核心成员心灰意冷，转投谷歌。另一个结果，就是苹果，这家在13年前站在AI前沿的公司，在2022年末OpenAI带来的这场技术浪潮开始被远远甩在后面。

二、

三剑客John Giannandrea、Craig Federighi、John Terners与苹果AI的新技术路线图

终于，ChatGPT的一记天雷震醒了苹果的迷梦。在2023年的每次业绩电话会里，股东们关于苹果AI发展的提问都成了媒体关注的中心，库克缺从没有透露过AI计划的细节。

但在这一年里，苹果其实在暗中开足了马力：明确业务路径、巨量资金投入，团队调整，跨部门通力协作。低调一年，它准备在2024年翻盘再来过。

虽然成效现在还不显著，但通过观察团队变化和技术论文，我们还是可以拼凑出2023年苹果都做了什么，2024年它打算拿出什么。

根据多位曾在苹果公司从事机器学习的工程师称，苹果公司的领导层似乎更重视“边缘AI”，即在设备上而不是在云服务器上运行AI模型软件。Apple的AI战略，从来不在科技大厂争相发布的“越来越大、越来越强”的基础大模型。与依赖云计算的大型语言模型不同，边缘AI在本地设备上运行，无需云服务器或互联网连接，从而提供更快、更安全、更可靠的AI计算性能。

根据IDC的数据，2023年，iPhone以20.1%的占有率居市场第一。据不完全统计，苹果可能在全球覆盖大概十亿台左右的终端设备，这就意味着，一旦在iOS中集成了新AI功能，它将迅速覆盖数十亿台设备，影响数亿用户。**这种市场准入优势是其他公司所不具备的。**

1、**团队发力，追上版本更新**

苹果并不缺少人才，现在需要的只是让他们成为有权改变现状的人。

虽然Giannandre在2023年之前都对大语言模型的能力有所怀疑，在今年初才被各路Chatbot的演示彻底说服。

但他还是对大语言模型有所准备，在四年前就组建了Foundational
Models团队来开发这一新技术。它的原始团队正是之前提到的那个试图重塑Siri的黑鸟项目团队，其领导者是Java的缔造者之一Van
Hoff。在黑鸟项目失败之后，他转向了大语言模型的探索。2021年，在谷歌工作了15年的神经网络学习大神Rouming
Pang加入苹果，成为Foundational
Models团队的新负责人，在2023年，他开发的Axlearn训练架构帮助苹果有了开发大模型的基础。这三个人就是苹果AI项目中最核心的三剑客。

这一过去在苹果中并不核心的团队终于有了足够的资源去实现他们的野心。在Information9月6日报道这一团队时，它仅有16个人，但已经足调动每天数百万美元的训练经费。这一年里他们在从Ajax
GPT开始，一步步提升能力，直到年末推出能装进手机里的多模态大模型，追上了AI发展的最新版本。

![](https://inews.gtimg.com/news_bt/OfrDHLueW-3RtsITGxEYGdb4h4D0PqPro6k62M7k177LgAA/1000)
_图注：Information披露的苹果大语言模型核心架构，三剑客都在这张图里_

2、**三剑客John Giannandrea、Craig Federighi、John Terners再造苹果AI路线图**

目标是iPhone上能运作的AI，那技术路线也就相对明晰了：训练一个新的端侧模型，用它再造一个新Siri，来充当AI时代里苹果产品里的新大脑。如下图所示，基本三剑客的最终目标，都指向于此。

![](https://inews.gtimg.com/news_bt/OFbB1td-
Fj6xlNXPxeBqkkxFTOKr5Z70t1mGOLAK6Jk9cAA/1000) _三剑客从基础大模型、软件工程、硬件三个部分共建苹果AI_

John
Giannandrea的基础模型团队，承担了基础大模型研发、多模态、端侧模型、空间计算等多个关键技术的研发，目前可以看到的成果是：这个团队训练的Ajax
GPT训练参数量可能超过2000亿，或许功能上强过当时被当做业内能力基准的GPT-3.5。在2023年末，又低调发布了Ferret多模态大语言模型，这个模型支持文字、声音、影像的多模态输入；并通过其独特的混合区域表示技术，有效地识别和描述图像中的复杂空间关系。此外，Ferret模型在执行语言模型推理任务时表现出比较高的效率。与以往苹果对外的封闭态度不同，这次也可能和John
Giannandrea的理念相关，苹果开源了Ferret的代码和丰富的GRIT数据集，也进一步证明了其在多模态理解和生成任务中的潜力。

LLM移动设备可用化技术开发方面，2024年1月14日我们看到苹果更新了一篇论文（https://arxiv.org/pdf/2312.11514.pdf），主要关于如何在内存受限的设备上高效地进行大型语言模型（LLM）的推理。苹果研究团队提出了一种新的方法，通过将模型参数存储在闪存（flash
memory）中，并根据需要将其动态加载到动态随机存取内存（DRAM）中，从而解决了LLM在资源受限设备上运行时的挑战。

用通俗但不太精确的语言解释就是：

这些语言模型通常需要很多内存来运行，但如果设备内存有限，就会遇到问题。苹果想出了一个新点子：**他们把语言模型的参数（就像是模型的大脑记忆）存储在闪存里**
，这是一种存储空间比较大但速度慢一些的存储方式。然后在需要的时候**，再把这些参数临时搬到动态随机存取内存（DRAM）里**
，这是速度更快但空间有限的内存。这样做的好处是，**可以根据需要只搬运必要的参数，而不是全部搬来搬去** ，这样可以节省时间和内存。

**他们用了两种技术来实现这个想法：**

**窗口化**
：这个技术就像是在看一本书时，你不需要每次都从第一页开始看，而是只看你当前需要的那一部分。在语言模型中，这意味着我们只加载那些之前已经激活（就像是被用过）的神经元，这样可以减少重复加载相同的信息。

**行列打包：**
这个技术是利用闪存读取大段连续数据时速度更快的特点。想象一下，如果你要搬一堆砖头，一次搬一整堆比一次搬一块要快得多。在处理数据时，我们把相关的数据打包在一起，一次性读取，这样可以提高效率。

通过这些方法，即使设备的内存不是很大，也能运行那些比内存还大的模型，而且运行速度比原来快了很多。这就像是在一个小房间里，通过巧妙地安排，也能举办一场大型派对。这样的研究成果让那些内存有限的设备，比如手机或者平板电脑，也能用上先进的语言模型了。

除了基础模型团队的努力之外，由Craig
Federighi领导的软件工程部门要能让Siri这个核心基础发展出更多的符合用户使用习惯的功能，比如提供Siri和Messages应用程序自动完成句子的功能。同时他们还会将大语言模型集成到Xcode等开发工具中，这样新版本iOS的应用程序开发人员就能像有Windows
Copilot一样更高效的编写新的应用程序。而由Eddy
Cue领导的服务部门则需要去探索如何在其他苹果生态的软件中应用最新的AI技术，比如在生产力工具Keynote中去自动生成PPT。

第三路是John
Terners带领的硬件团队。与依赖云计算的大型语言模型不同，**边缘AI在本地设备上运行，无需云服务器或互联网连接，从而提供更快、更安全、更可靠的AI计算性能。**
“边缘侧AI”如何能跑得快、跑的准，是保证用户体验的两个先决条件。满足这两个条件一个是足够强大的硬件支撑（芯片等）、另外就是软件硬件结合的强大能力。以苹果最新发布的A17芯片为例，它被行业用来与竞品高通发布的骁龙8Gen3芯片对比，两款芯片在各项能力上不相上下。骁龙8Gen3被官宣可以支持百亿参数大模型在手机边缘侧运行，而苹果的A17芯片，并没有宣布端侧支持AI模型的具体能力。但从芯片的具体参数对比来看，这对于苹果来说，似乎并不是难事。除了手机端，PC端的AI能力，也是市场关注的焦点，而M系列芯片，专门为Mac产品线而设计。我们也可以期待，是否今年苹果硬件的升级中，会明确提出如何去支持AI功能的升级。

当基础模型能力、软件能力、硬件算力能力三路会师、齐头并进，我们可以期待，是否会有一个新的苹果的诞生。

三、苹果收购32家AI初创公司，远超谷歌、Meta、微软

从被诟病的Siri开始，苹果其实完全没有停止在机器学习领域的持续投入，通过下图我们可以看出，苹果在计算机视觉、自然语言处理、多模态等领域都有成果发布。

![](https://inews.gtimg.com/news_bt/O5i_YKSZLpB0UKkLMg-qhTR67A9PN_-
EC_qxm4Z4RU5wMAA/0)

与外界对其“佛系”的印象不同，其实苹果是在AI领域收购最为积极的公司，根据Stocklytics.com的数据，到2023年，苹果购买了多达32家AI初创公司，这是科技巨头中数量最多的（谷歌21家，Meta18家，微软17家）。

Stocklytics的金融分析师Edith Reads对这些数据发表了评论：

在持续的AI军备竞赛中，苹果正在与许多AI初创公司进行大规模交易，主要为了在未来发展中占据有利位置。通过收购有前景的AI初创公司，苹果获得了顶级人才和核心创新技术，并在关键的AI领域巩固了其地位，确保在迅速变化的技术环境中保持竞争优势。

苹果的投资策略侧面反应了苹果在AI领域的关注重点，包括AI人才、关键技术和知识产权。

早在2020年，苹果公司就收购了Voysis，这是一家参与制作数字语音助手的AI初创公司，这些助手自然地帮助理解自然语言。苹果收购该公司的目的是改进其设备中的虚拟助手Siri。

苹果还在2023年3月收购了WaveOne，其技术有助于大量视频压缩。苹果获得的其他技术包括Emotient、Laserlike、Drive.AI和AI.Music，其中一些已经嵌入到iPhone、Apple
Watch和Mac中。

苹果收购狂潮的一个显著特点是其强调**收购早期阶段的初创公司** ，这表明了一种积极的战略，即在AI趋势和技术达到主流采用之前，识别并投资于它们。

![](https://inews.gtimg.com/news_bt/ORcmjU1snP27swyLHuNTThSTPZjAVMddnvRUcAFqZlx9gAA/1000)

四、

在AI时代，苹果还能做智能设备的王吗？

去年除了大模型及其应用以外，在AI行业被讨论最多的是一个话题，未来的智能终端设备还是手机吗？如果不是手机，AI原生的智能设备将是什么形态？

Ai Pin， Rabbit R1的答案是不需要。他们缩小了设备，简单化了交互，甚至干掉了屏幕。

但人是视觉动物，在屏幕技术没有被另外一种视觉技术取代时，不管交互如何变化，应用怎样发展，我们都需要一个屏幕。那这个AI智能设备的形式就会和在便携性和体验间探索平衡的智能手机相差不远，除了芯片外的硬件底层也不会差太多。

而最有潜力替代传统屏幕的显示技术XR，苹果也已经用Vision Pro站住了生态位。

如果还是手机，什么才是真正的AI手机，我们和主要终端厂商的AI团队聊过，大家的共识是，打破应用壁垒，垂直整合端侧应用，通过用户一个指令，就能够调动千军万马（各个APP）自动帮助用户解决需求。这需要终端厂商有强大的生态整合能力，且对每个APP有足够的话语权。而苹果在这方面，确实有足够碾压的优势。路线上，苹果还可以是王。

时间上，2024年发布第一代结合GenAI的系统其实并不算慢。生成式AI在设备上的应用离成熟还相差甚远。比如苹果的主要对手谷歌在Pixiel上搭载了很多AI功能，但大多都是如AI一键抠图，信息自动回复之类零碎添头，并非能够彻底改变体验的产品。它的拳头产品Gemini甚至到了2023年底才有了App本体。AI在智能手机上的应用还很不充分，这一方面是因为应用模式还在探索期，另一方面也是因为当下端侧算力能够承载的生成式AI能力还很有限，而这两个问题都很有希望在2024年得到初步解决。

苹果入局的现在，才是游戏开始之时。


# 怕AI毁灭人类，马斯克呼吁暂停开发，炒作还是“打嘴炮”？

![](https://inews.gtimg.com/news_bt/O8N3ozxVki2GIMSM0rq_RF5s7qnxmnmYJzhwwGrmZ-3FcAA/1000)_《AI未来指北》栏目由腾讯新闻推出，邀约全球业内专家、创业者、投资人，探讨AI领域的技术发展、商业模式、应用场景、伦理及版权争议。_

**划重点**

  * _1_ 警惕AI发展，防止AI失控，正在成为全球范围内科技领域的“政治正确”；
  * _2_ 在严防人类自我灭绝的问题上，很多风险如核大战、气候变化、致命病毒传播、生物科技滥用等要排在超级AI之前；
  * _3_ AI可能导致各种社会风险，学界早已指出，各种应对建议也早被提出来，现在的问题是根据国情落实AI治理措施，不是暂停研发；
  * _4_ 如果不做政策上的总体安排，ChatGPT肯定会导致大量“AI失业”，反过来“AI失业”又会阻碍ChatGPT的进一步应用。

**文 / 刘永谋 中国人民大学哲学院教授、国家发展与战略研究院研究员**

2023年3月，包括埃隆.马斯克在内的千名专家联合签署公开信，呼吁暂停训练GPT-4后续人工智能（AI）模型至少6个月。消息一出，引爆全球网络和媒体，很快引来吴恩达等“AI大牛”的反对。最后，此事也没有下文，暂停GPT-4被怀疑就是OpenAI的一波炒作。

4月份，又传出意大利要全面禁止ChatGPT，不久的结果是罚款了事。

5月份，美国总统拜登和副总统哈里斯也来凑热闹，与顶级人工智能企业谷歌母公司Alphabet、微软、OpenAI和Anthropic的首席执行官举行会议，向企业施压围绕人工智能实施保障措施，表示支持新的法规或立法，减轻AI技术的潜在危害。

![](https://inews.gtimg.com/news_bt/OXROz9vjX1MTMgD5jbIYkIGYODZX2tFlqcyeUsWb0k1EAAA/1000)_用户利用生成式AI工具制作的“马斯克和他的AI女友”
图源：网络_

**一切看起来山雨欲来，似乎ChatGPT、Midjourney、DALL-E 2为代表的生成式人工智能（GAI，Generated
AI）催生了新的、更严重的社会风险**
，使得人类社会发展和应用AI技术的总体局面发生了根本性改变，需要采取新的战略、措施和办法来应对，比如全面暂停新的AI技术的研发。

真的是这样的吗？否。

第一，GAI并没有产生什么新风险，它可能导致的问题早已也一直被学界所讨论、所呼吁。

第二，应对GAI风险并不需要什么新方法，应对AI风险的关键一直都是落实。

4月11日，国家互联网信息办公室公开发布《生成式人工智能服务管理办法（征求意见稿）》，以前所未有的速度对GAI作出治理反应，佐证GAI应用社会影响巨大，必须认真研究，审慎地而迅速地加以应对。

**01 谨防AI失控——全球科技领域的“政治正确”**

就目前已经暴露出来的迹象来看，GAI挑战最大的领域至少包括3个：

1）失业问题，即它可能导致文案策划人员、原画师、工业设计人员、程序员、媒体从业人员和翻译人员等脑力工作者大量失业。

2）教育问题，即它可能冲击既有-的教育科研系统，比如学生可以用ChatGPT代替自己做作业。

3）信息安全问题，即GAI自动生成海量的人工智能生产内容（AIGC，AI Generated
Content），真伪难辨、立场可疑，权属不清、追责困难，甚至可能成为挑战主流价值观和意识形态的危险工具。

AI风险早就被各国政府所重视，近年来更是成为全社会的关注焦点。显然，上述GAI导致的三大冲击都不是什么新问题，早在ChatGPT爆火之间就已经被学界和政府所关注、所研究。

近十年来，从物联网到大数据、云计算、区块链、元宇宙、ChatGPT，一波波的AI热潮中，从来没有缺少关注风险的呼声。

本人专业关注新科技社会冲击问题，花了大量精力提醒大家注意AI可能导致的技术风险。比如，曾写过专著《技术治理通论》《物联网与泛在社会的来临》《技术有病我没药》《元宇宙陷阱》《科技与社会十四讲》，面向非专业人士提示ICT（信息与通讯技术）的社会冲击和技术风险。

可以说， **警惕AI发展，防止AI失控，正在成为全球范围内科技领域的“政治正确”。**
在此氛围之下，公开宣称“AI无禁区”的声音被极大地抑制。对此，作为技术控制的选择论者，我完全赞同。

就目前的发展态势而言，ChatGPT究竟存在什么严重的风险，必须以“加码”的方式比如暂停至少六个月加以应对呢？

有人说，ChatGPT是超级AI出现的征兆，如果现在不停止（注意：不仅是暂停），“潘多拉的魔盒”一旦打开，人类很快会被超级AI统治甚至灭绝。这种幻想色彩浓厚的念头，很难让人予以严肃的对待。尤其是，很多专业人员不承认ChatGPT是通用AI，更别说它是超级AI的雏形了。

**超级AI可能是个问题，但在严防人类自我灭绝的问题上，很多风险如核大战、气候变化、致命病毒传播、生物科技滥用等要排在超级AI之前。**
我们是不是先把它们都停止了？就算停止不了，暂停一下也行，起码可以呼吁暂停。

既然没有什么新的情况，就不必采取暂停发展的极端方法，为什么？

第一，暂停是没有道理。有人说，ChatGPT风险应对措施没有想清楚，所以先暂停。错！不是没想清楚，而是没有落实到位。

第二，暂停是不可能真正实现的，肯定会有AI公司会违反禁令，结果是不公平的竞争。

第三，暂停解决不了问题。就算所有AI公司真的都暂停GAI科研，风险问题就解决了吗？没有！除非彻底停止和取缔LLMs（Large Language
Models，大语言模型），否则风险不会消失。重新启动之时，仍然得直面风险。

如今，新科技是人类生存和发展最重要的不可须臾离开的工具。GAI对社会生产力的推动作用已经昭然若揭，我们为什么要因噎废食，为什么不能控制地利用呢？

20世纪就有人提出——当时的科技人类已经完全够用了，继续发展会导致很多新问题，应该让科技静止下来，科学家不要再搞研究了。此类极端非理性想法，从来没有被社会严肃对待过。

**02 暂停GAI研发实现不了，纯属无效的“嘴炮”**

AI可能导致各种社会风险，学界早已指出，各种应对建议也早被提出来。因此，现在的问题是根据国情落实AI治理措施，而不是暂停AI研发。事实已经证明：
**暂停GAI研发的想法简单粗暴，作用不大，也实现不了，纯属无效的“嘴炮”。**

举AI失业问题为例。AI失业问题，即人工智能的推进伴随着越来越多的人失去工作，是AI社会冲击中最大的问题，涉及到整个社会的综合性制度创新。既有文献对AI失业问题的讨论，可谓汗牛充栋，具体的应对措施不一而足，如学生的职业规划、劳动者AI素养提升、失业人员社会保障和再就业、产业结构升级改造等。

长远的战略规划亦蔚为大观，如制度性地减少劳动者工作时间（有些地方已经在尝试一周工作4天），征收AI税（AI是全人类智力结晶，向AI公司征收重税全民共享），灵活退休制度（劳动者一辈子可以短暂退休几次）等。

AI应用对当代治理活动最大的影响在于：扩大经济自由，增加闲暇时间，极大地改变公共治理的前提条件，从而改变社会运行的根本面貌。但是，这种影响也意味“AI失业问题”越来越严重，给整个社会的治理活动带来严重挑战，必须审慎地加以处置。AIGC产业化将再一次证明AI失业问题的严峻性。
**如果不做政策上的总体安排，ChatGPT肯定会导致大量“AI失业”，反过来“AI失业”又会阻碍ChatGPT的进一步应用。**

![](https://inews.gtimg.com/news_bt/OcbTbyvI4MbBfRomuXAaNR6gIZ-
SgOP3zWRe_mLcOLm1kAA/1000)_漫画：机器人接管重复性工作，例如制造和包装 图源：TC_

“AI失业问题”的解决，必须同时考虑远景和现实两方面。

从远景来看，“AI失业问题”要解决，牵涉到人类社会制度的根本性变革，而不是仅仅靠智能技术和智能治理的发展所能解决的。根据马克思主义基本原理，“AI失业问题”反映出科技生产力发展与既有生产关系之间的矛盾。机器人能够取代人类劳动，并不等于实际取代人类劳动，因为此种取代意味着取消少数人通过制度安排强迫大多数人进行劳动的剥削制度。从本质上说，解决“AI失业问题”，要不断减少劳动者的工作时间，给人们更多的闲暇时间，最终必须要彻底消灭剥削制度。20世纪的劳动史表明：现代科技在生产中的运用，持续减少着社会必要总劳动时间，推动“八小时工作制”和“双休制”被越来越多国家所实施。

从现实来看，社会制度进化需要很长的时间，必须逐步稳妥地前进，而且也要等待智能技术不断地发展，所以当务之急的问题是给受到人工智能冲击的劳动者找到新的工作岗位，保证他们能享受科技进步创造的物质财富。

因此，在AIGC产业化爆发之初，国家、政府和社会应该深入研究，全盘规划，积极应对可能出现的失业就业压力。

比如，完善失业保障和提供再就业培训服务，加强青年人的职业规划和创造性素质提升，调整学校人才尤其人文、艺术等学科的人才培养方向，不端推动产业升级创造新的就业岗位等。总之，面对AI可能伴随的失业风险，必须要放弃非此即彼的极端思维，努力规避，实时调整。

**03 中国的AI如何治理？**

建设数字中国是数字时代推进中国式现代化的重要引擎，是构筑国家竞争新优势的有力支撑。

在数字中国建设中，必须推进“以人民为中心”的AI治理，使得AI能真正地造福社会。为此，首先就要呼吁全社会都来关注AI风险问题，政府、企业、NGO、科技界和公众按照职责分工，完善政策措施，强化资源整合和力量协同，形成行动合力，把治理AI风险的各项方案真正落实下去。

除此之外，治理AI风险还可以考虑如下原则性建议：

第一，贯彻有限工具原则。必须清醒认识智能治理的作用——智能治理并非万能的“完美利器”，在很多情况下同样会“失灵”，甚至走向妨碍社会效率的反面。因此，既要承认在某些领域、某些问题和某些场合下智能技术提高治理效率的作用，力主优先考虑技术治理手段解决问题，又时刻谨记智能技术作用的有限性。坚持科技谦逊主义，警惕“大数据迷信”，采取具体语境具体分析的审度态度，重视治理活动实际的效果反馈和风险控制。

第二，坚持利用与控制并重。既要发挥智能治理作用，又要对具体的智能治理进行控制，防止智能平台和技治专家权力失控。同时，应运用制度-
技术的方法，规避智能治理可能导致的社会风险。

第三，妥善处理“AI失业问题”。智能技术应用对当代治理活动最大的影响在于：扩大经济自由，增加闲暇时间，极大地改变公共治理的前提条件，从而改变社会运行的根本面貌。但是，这种影响也意味“AI失业问题”越来越严重，给整个社会的治理活动带来严重挑战，引起全社会的关注，必须审慎地加以处置。

第四，紧密融合“智慧城市”和“数字乡村”建设。科学地运行城市是当代技术治理重要的战略措施，智慧城市则是科学城市的高级形态。由于当前人类主要生活在城市尤其是大型和超大型城市之中，因而当前的智能治理主要围绕建设“智慧城市”而推进，或者说以“智慧城市”的建设为主要载体。数字中国建设尤其不可忽视数字乡村建设，要努力以数字化缩小城乡差距。

第五，注重智能技术与人的融合。在技术治理活动中，技术与人结合得越好，治理效率越高。加强智能治理活动中人与技术因素的融合，需要从各种智能技术的特点以及相关伦理、法律、心理、危机管理等诸多层面进行系统反思，推进制度建设、技术研发和人才储备，加强组织领导、专家咨询和实战演练，不断系统地提升中国的智能治理能力。

第六，在具体语境中区别治理与操控。智能治理有限度，超过限度就成为智能操控，侵害公民的基本权利。智能治理的未来发展，必须要具体考虑各种应用的限度，这不仅涉及治理目标，还涉及所采用的手段，只能在具体的社会语境中加以冷静、客观和谨慎的审度。防止智能治理走向智能操控，一个很重要的问题在于：必须在一定程度上容忍智能治理的反治理行为。

**本文独家发布腾讯新闻，未经授权，请勿转载。**


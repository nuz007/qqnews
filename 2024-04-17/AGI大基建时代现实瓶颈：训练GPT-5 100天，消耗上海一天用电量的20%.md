# AGI大基建时代现实瓶颈：训练GPT-5 100天，消耗上海一天用电量的20%

# AGI大基建时代现实瓶颈：训练GPT-5 100天，消耗上海一天用电量的20%

![](https://inews.gtimg.com/om_bt/OnS_S9RRhanLdo3WfwEt-
waasKt55dlDDY3Q-sb83pToIAA/1000)

作者：张小珺

出品：腾讯新闻《潜望》

2024年3月，我们连续从多个角度记录了中国AGI的进展与派别，接下来让我们把目光投向海外，对刚过去的2024
Q1全球大模型的赛局做一个实时的赛况观察与复盘。

[王小川：中国AGI的第三种可能性 ](https://news.qq.com/rain/a/20240314A007VK00)

[朱啸虎讲了一个中国现实主义AIGC故事 ](https://news.qq.com/rain/a/20240306A00LZ800)

[月之暗面杨植麟复盘大模型创业这一年：向延绵而未知的雪山前进 ](https://news.qq.com/rain/a/20240229A0990C00)

**“AGI本质是：电+芯片=产出智能。”** 拾象科技CEO李广密称，他此前是红杉资本投资人。

**人类正处于一场宏大的“AGI大基建”时期。**
“这和曼哈顿计划、登月计划、克林顿网络大基建很像”，特别是上世纪九十年代，克林顿推出美国信息高速公路建设，为后面的美国互联网泡沫破裂与黄金20年提供了根基。在他看来，“如果没有基建，就不可能有应用大爆发”。

从基建维度，以训练一个GPT-4举例——据李广密估算，在耗电上，假设GPT-4使用8000张H100训练100天，大概需要2600万度电，大约需要三峡或上海一天发电量或用电量的5%，德州的2%；在算力上，现在最低要8000张H100有效算力，接近一个万卡集群，如果买卡，每张H100售价3万美元，再加上周边设备，3亿美元少不了，而如果租H100，1万多美元一张卡，也就是1亿到2亿美元。

随着大模型公司的加速收敛，全球看，2024年模型公司的生死线是：在技术上，年内超越GPT-4；在算力上，年内万张卡集群，而且要能用起来——**“你就看未来12个月能不能有10万张H100的集群，这大概需要三五十亿美元，这是明年第一梯队模型的标配。”**
他说。

李广密对海外AGI的前沿进展有一手观察。他称，计算的竞争很残酷，未来只会更残酷，“每个时间阶段都会有模型公司持续的出局”。

以下是关于2024 Q1全球大模型赛况的对谈手记。（为方便阅读，作者进行了文本优化）

01 谈2024 Q1：没想到，物理硬件成了阻碍AGI时间表的最大因素

**腾讯新闻《潜望》：** 我们先来盘点一下美国AI几起大事件：从过年到现在，OpenAI发布Sora，Anthropic发布Claude
3，Google和马斯克加入开源大战（分别推出Gemma和Grok），英伟达GTC被冠以“科技界春晚”头衔。

这一系列大事有没有什么让你感到shock的？他们分别对今年大模型战局或更长时间的AGI演进，影响多大？

**李广密：** 1、GPT-4.5和GPT-5比预期来得慢，之前以为Claude 3发布后OpenAI就发新模型了，你看SOTA（State-of-
the-art）模型位置易主一个月，**我预感AGI战线会被拉长拉宽。**

2、Sora比预期来得早，这意味今年多模态理解和生成进步幅度会很大，会解锁很多新东西，但多模态能否带来智能和AGI是很强非共识。

3、**马斯克xAI加入开源，开源模型水位线会被拉升很多。** xAI人才密度强，GPU也充足，决定后面很多模型公司生死线。

4、英伟达股价去年这时候觉得会涨，但没想到能涨3倍。大家都知道AGI很大，但还是低估了浪的大小。英伟达GPU是实现这轮AGI最关键的吧。短期看，老黄（黄仁勋，英伟达公司创始人兼CEO）可能比Sam
Altman（OpenAI联合创始人兼CEO）重要。

**腾讯新闻《潜望》：** 同时加入开源战局的有Google，你对Google开源的看法是什么？

**李广密：**
Google发的还是小模型，我感觉它不会把最强模型发出来。开源主力是xAI和LLaMa。**我比较担心，开源模型会打掉很多闭源模型的商业价值**
——比如你把GPT-3.5水平的模型开源了，大家就不一定再调用OpenAI的API接口；反之没有开源模型，大家只能选择最强模型的API。

但最强闭源模型的优化能力很强——最强模型能力最强，成本最低，我相信这个状态。后面还有“复杂推理”，要完成有经济价值的任务。如果多步推理准确性差，是完不成任务的。但现在很多简单任务，开源模型可以完成。

开源模型有开源模型的好处，很多人拿它自己用更好用，会覆盖很多企业内需求场景。

**我不确定马斯克xAI会不会持续开源，如果它开源，开源模型水位很高。**

**腾讯新闻《潜望》：** 马斯克的开源模型，为今年大模型争夺赛带来了很大变量。

**李广密：** xAI是全球范围争夺新一梯队大模型的唯一黑马。如果它持续开源，对模型的格局生态和商业价值影响很大。

**腾讯新闻《潜望》：** 你说“多模态能否带来智能和AGI是很强的非共识”，对于这点你怎么看？

**李广密：**
多模态有几层作用：一是文本数据不够用，可以补充文本数据；二对用户体验有很大影响，理解能力变强；三是生成视频的效果今年也会大幅提升。但多模态的数据对模型推理能力有没有大幅提升？今天没验证。Sora到底是不是AGI主线？今天见仁见智，很难定义清楚。

**腾讯新闻《潜望》：** 相比去年，今年翻过年的这个季度，有没有什么让你感到明显不同？

**李广密：** 去年初觉得AGI是百米冲刺，大家没做好准备。**今年觉得AGI是马拉松，大家有充足时间做好准备。**

**去年觉得可以无限加GPU，加数据，就能到AGI，但突然发现GPU数据中心和物理硬件是瓶颈。**
比如单体数据中心能放的GPU数量有限，3.2万卡再往上就要突破很多。另外美国的能源基建都是四五十年前规划的，能源结构和中国工业结构不同，突然多出来很多新增用电确实有点跟不上——今年最大感受是，物理硬件成了阻碍AGI时间表的最大因素了。

**腾讯新闻《潜望》：** 2024年，全球大模型场上的梯队有哪些新变化？

**李广密：**
OpenAI、Anthropic、Gemini是非常确定的第一梯队。xAI、欧洲Mistral、LLaMa是比较确定的第二梯队。xAI是硅谷最大而且可能唯一的黑马，期待夏天or年底前能不能做出GPT-4水平模型，冲到第一梯队。

**Inflection已掉队出局，Character.AI、Cohere今年挑战很大，有可能年内就要找买家。**
训练GPT-4水平的模型很难，很多人还没真正规划训练GPT-4水平模型。

**腾讯新闻《潜望》：** Inflection提供了一个怎样的失败案例？——有人说它是第一个失败的VC重注的大模型公司。

**李广密：** 没想到模型收敛如此之快，**计算竞争是很残酷的。**

**大模型VC是投不动的，还是巨头的游戏。** Inflection没有绑定一个更深的巨头。另外，要看人才密度，前三家公司加上马斯克的xAI明显高一截。

**腾讯新闻《潜望》：** 能不能聊聊对今年GTC的感受？怎么评价老黄这个人？

**李广密：** 硅谷最靓的仔从马斯克切换到老黄了，很多马斯克的粉丝变成老黄的粉丝，投资者股票资金也从Tesla转到英伟达。

老黄直接驱动了这波AGI浪潮，贡献不输OpenAI。之前听到一个说法是“算法等了算力30年”，非常形象。我希望AGI不要因为算力不够而停下。你看过去几十年，半导体应该算得上人类最伟大发明，计算还会驱动未来几十年。未来几十年人类都要给老黄缴算力税——这就像过去十年所有人给苹果交入口税。

**老黄“销售能力超强”。** 以前
GPU卖给科技公司，现在又提“主权AI”，要把GPU卖给政府，吃国防预算，市场规模又大一步。你看美国军费每年8800亿美金，如果拿2-3%买GPU，是很大的量。你说GPU是不是很重要的战略储备物资？是极其重要的。

另外，老黄有一个习惯，叫T5T——内部每双周、每个大组内会发出最重要的五件事。

老黄好像不鼓励996，鼓励员工在办公室吃早饭和午饭，但鼓励大家晚饭回家陪家人。

02 谈AGI登山图：南坡是模型，北坡是产品

**腾讯新闻《潜望》：** 接下来我们来谈谈AGI。首先定义一下AGI，对AGI的定义现在是共识吗？

**李广密：** 对AGI的理解还没共识，有几个角度：

1、最激进情况，AGI能在90%行业、超过90%专家、完成90%有经济价值的工作——这三个90%很激进。Sam提过，不该从替代人的视角思考，而是工作任务中多少需要5秒就能完成，这些会被模型取代。

2、AGI什么最重要？智能能力本身最重要。今天讨论什么形态可能不重要，什么载体也不重要，最重要的是智能能力本身，但肯定会从数字世界走向物理世界。物理机器人和设备，怎么把智能能力产品化，是创业者的机会。

3、AGI不是一蹴而就，不太像是憋几年大招在某年实现AGI就把所有秒杀——**关键词是“渐进式解锁”**
——如果画一条登山路线图，模型能力每年涨一些，就会解锁一些场景，诞生一些应用，创造相应经济价值。

听到最强叙事是，AGI可以在未来15-20年帮全球GDP翻倍，从100T（trillion，万亿美元）涨到200T。但今天100T
GDP和这波AGI直接相关的可能0.1%不到，离解锁90%很遥远。目前就体现在Coding写代码效率高，信息检索和复杂问题问答效率在提高，往后10-20年是从今天只解锁0.1%走到解锁90%的过程。

一定要理解“渐进式解锁”。我们一直在画一个路线图，未来AGI登顶过程分别有哪些东西？——**眼前我最期待的是改变软件生产方式+信息检索的变革。**

**腾讯新闻《潜望》：** 先从近处看，眼前是改变软件生产方式+信息检索的变革，也就是说，它会颠覆SaaS行业和Google？

**李广密：**
三年内有机会看到Coding领域的局部AGI，也就是任务做得不错的程序员，带来软件生产方式革命。人类大部分任务没有像软件开发那样有明确的目标和逻辑，软件生成变革会最快。

改变软件生产方式：过去软件像自动售卖机，有限SKU供给，有大量长尾非标需求没被满足。未来应该是酒吧调酒师，任何口味都可以调出来，长尾需求大。

未来的软件开发状态是，精准的甚至简单的自然语言描述需求，模型如果能用现有工具就调用工具解决，如果没有满足的工具，那模型编程，甚至生成复杂的代码，自己run
code（运行代码）或debug（调试），会多出非常多软件程序。开发者数量可能不是今天的几千万，而是人人都是，门槛大幅降低。有可能微软+OpenAI会很激进，把很多工具feature型的SaaS干掉，只有积累复杂workflow和很不一样数据的能发展更好，如Salesforce、ServiceNow。

挑战Google：**过去20多年，无数对手挑战Google都失败了，很大原因是没有fundamental技术变革，这一次LLM给了大家机会。**
另外，Google绝大多数是事实性搜索，如电商、旅游、YouTube网站，问答一直很难，是皇冠上的明珠，解决很难的问题后更能得到用户的信任，有更长期的用户留存和广告价值。

**腾讯新闻《潜望》：** 在这种情况下，你建议SaaS公司如何转型？

**李广密：**
只能拥抱年轻人。以前软件开发的方式跟现在软件开发的方式有fundamental（根本性）不同。以前是把固定需求抽象出来，一个开发团队去开发，今天是不确定的需求，未来要用好模型的能力。

**腾讯新闻《潜望》：** 更长远看，AGI对于人类社会可预见的改变，在多长时间的维度中能有多大？这波浪潮中将诞生的巨头会比互联网时代更庞大吗？

**李广密：** AGI是科学问题，不完全是商业问题，背后是永无止境research发现精神，探索全新的一些能力，即**“能源+芯片=产出智能”**
。未来就看智能产出效率能有多高，你看智能怎么定价？

科技进步是创造增量经济价值贡献最大的要素，每波技术变革都能让头部公司大一个数量级。之前做VC觉得投到独角兽就很牛，**今天融资单位都是billion级别，钱也毛了。**

我有一个切身体会：2010年你看着2000多亿美元的苹果，不会想象地球上能有1万亿美金市值的公司。2016年我们看着英伟达从200多亿美金涨到千亿美金，更不会想到能涨到今天这么大。还是回到今天最大非共识：不知道AGI有多大。

最简单叙事，AGI是以全球GDP为计量单位，未来你能渗透到GDP take
rate百分比，如果你增加100T，AI拿走10%，就是10T，或者多出3亿白领乘以3.3万年薪，也是10T，这还是收入，市值乘以10倍吧。计量单位发生了很大变化。

**腾讯新闻《潜望》：** 很有意思，今天融资单位变成了billion级，这在中美的商业史上出现过类似情形吗？

**李广密：**
为什么把AGI比作大基建？中国做了很多，如公路建设、电信5G建设、城市化建设，有了这些才有短视频、直播、外卖爆发，这是远超billion甚至trillion级的基建投入。甚至电商、物流建设也都是巨大投入。今天AI投算力、投新型数据中心，就是处在基础大基建状态，这是一直在发生的。

你再看美国比较早的有曼哈顿计划造出原子弹，更重要的是计算机体系在那诞生，再后来美国登月。美国登月一个重要意义在于电子产品微型化，才有了个人电脑。93年克林顿推出美国信息高速公路建设，投了GDP的5%，才有了后面的互联网bubble（泡沫）也好，美国互联网黄金的20年也好，都跟基建有关——如果没有基建，没法谈应用大爆发。

**腾讯新闻《潜望》：** 构建一下你眼中关键的AGI登山路线图？

**李广密：** 两面——南坡是模型，北坡是产品。

模型最底层逻辑是Scaling Law（规模定律），更多数据，更多GPU，更多能源，就看产出智能的效率能否持续提高。

模型最关键的能力是Reasoning推理能力，后面要有复杂推理能力，才能完成有经济价值的任务。**Coding代码能力很重要，可能是AGI落地最早信号，既是一个走向AGI的能力，也可能是核心产品，改变软件生产方式。**

多模态能力也很关键，不仅补充text data不够用，更重要的是输入输出交互效率更高，今年多模态进步会很大，对自动驾驶和机器人有提速作用。

Agent（智能体）也是关键词，但今天Agent还不太work，模型Reasoning推理能力不够强，准确度不够高，多步推理下做任务很多是失败的。**模型公司可能就是Agent公司。**
很多Agent，大模型本身就会自己做，只是能不能做好的问题。接下来模型公司一个大的附加值可能会体现在Agent，因为第一波叙事大家都讲了Scaling
Law，后面大家可能就会讲Agent。

这是南坡模型能力相关，你说北坡，产品上——就看接下来谁能做出上亿活跃用户的Killer
App（杀手级应用）。今天只有ChatGPT，**我期待信息检索有大变化，**
因为搜索之前搜出来是链接和网页，现在搜出来是答案。未来还有多模态的搜索，甚至更多主动式交互，模型直接推你潜在想要的。

从ChatGPT用户增长角度，它过去5000万DAU横盘几个月，如果它积极做用户增长，一定要做搜索才能突破几亿活跃用户，这是挑战Google过去20年可能唯一的技术窗口。今年比较期待看ChatGPT能不能做好这个。

**另一个我最期待的，如果你让模型看一万次苹果掉下来，它能不能发现万有引力定律？如果更充足、更广泛的数据灌进去，能不能发现人类没发现的问题和规律？这又是一个新的文艺复兴。**

**腾讯新闻《潜望》：** 模型和产品，这两个都要一家公司来做吗？有可能一家公司爬南坡，一家公司爬北坡？

**李广密：** 你看**Sam最新访谈说OpenAI在做地球上最难的两个事，一是AGI，一是Killer App。**
Anthropic专注只做AGI，没挑战另一个。不一定非得在一个公司，在一个公司对组织能力，对文化、人才和资源，挑战很大，需要极强的领导力、资源和组织能力。

**腾讯新闻《潜望》：** 模型和产品需要的人才画像不一样，怎么把他们组织在一起？

**李广密：**
画像很不一样。如果一个产品在解决某项任务的时候能力不行，没法向下改模型。如果一个模型公司发现某类任务解决不好，可以定向改数据、调模型。这是简单题和难题的问题。我相信模型公司做产品更容易，是顺手。产品公司想改模型，没有这方面人，你又改不了模型，是较难的。

我有一个判断，**有可能模型公司是价值沉淀最厚一个地方。** 就像移动互联网，价值沉淀到了设备厂商或广告平台，模型的附加价值后面是比较高的。

**一个是老黄收GPU税，一个是模型公司收智能税，突然给经济社会又加了两道税。**

**腾讯新闻《潜望》：**
所谓我的模型能力最强，我就可以顺理成章解锁最伟大应用，这个逻辑通吗？现在有两种做法——一种是，我要通往AGI，我在路上去解锁应用；另一种是，我也做AGI，但同时我孵化特别多应用，做App工厂。这两种你更看好哪一种？

**李广密：** 你就看SpaceX，它的火箭发射能力是基础能力，但这个能力并不太赚钱，可能每年几十亿美金收入，但是它的一个Killer
App是Starlink星链，现在几百万部署终端了，每个终端还收挺多钱。

如果没有火箭发射这个关键能力，Starlink发不上去，没法组网。有可能它还有第二个Killer
App，就是Starship，想颠覆波音、空客，未来上海到纽约两小时。之后可能还有更多Killer App。

但也有另一个说法，如果大模型是电，灯泡可能不一定是电厂做出来，所以在变化中。

我更倾向大模型公司是基础发现的research
lab（研究实验室），有的lab可能有商业能力，会做出头部应用，但比较考验组织能力。有可能中国创业者在这方面更强。

**腾讯新闻《潜望》：** ChatGPT和Sora分别属于AGI登山图上的什么路标？

**李广密：**
ChatGPT成功有偶然运气成分，让AGI概念进入千家万户，科普和募集资源的帮助更大，是里程碑。Sora和AGI、智能有啥直接关系还是非共识，只能说明OpenAI战线铺得更宽，而不是高度聚焦AGI。

**腾讯新闻《潜望》：** 复刻Sora难吗？模型规模有大？需要多少算力、数据？数据来源是什么？

**李广密：**
OpenAI没有公开Sora数据，但根据技术报告和里面提到的架构可以做估算。训练环节对算力需求是LLM的好几倍，**我们估计大约需要在4200到10500张H100上训练1个月，这只是最后训练，不算前期实验探索。**

推理的算力消耗要比训练更大，如果生成TikTok一天上传视频的量，推理成本就增加到了训练成本等同。这两个成本都很高。

另外数据，估计要收集几千万到上亿个小时的视频数据，还得打标签。OpenAI可以用GPT-4V打标签，一般团队不好弄。到底什么数据我们不知道，只能猜，你看Sora效果和游戏场景很接近，估计是用一些游戏数据。

OpenAI CTO Mira说得把推理成本降到和生成图片差不多的水平，才会考虑公开release Sora。

**腾讯新闻《潜望》：** 创业公司应该跟进Sora吗？

**李广密：** 很凶险。融资能力极强的公司可以试试，除非能融到几亿美金？

需要的数据难度介于LLM和机器人之间，获取数据的难度很大，卡和数据成本都很高。但最后产出结果还有争议性，视频生成还不一定代表智能。即便做了一个模型，如果不是业界最领先，别人也不一定用。

**创业公司还不如想想下一步，怎么定义Sora产品形态和新的AI内容消费形态。**

03 谈大基建：电+芯片=产出智能

**腾讯新闻《潜望》：** 我们把当下比作“AGI大基建时期”，目前AGI大基建最大瓶颈在哪？这些瓶颈是只要有时间就可以解决的吗？

**李广密：**
目前瓶颈是算力和数据中心建设，今天给你几万张H100，你三个月内不一定能用起来万张卡集群。万卡集群互联通信难度很大，稳定性要求很高。GPU数据中心能耗更高，对降温要求更高，很多人都在提液冷。

比特驱动的数字世界迭代很快，但原子驱动的物理世界迭代跟不上，这需要物理机器很长周期的基建迭代跟进。历史上软件和硬件进步是交替的，硅谷头30年是计算时代，后来20年是网络数字化时代，今天又进入了计算时代。

但好在这些物理问题都不是research问题，是工程基建投入问题，随着时间可解决。短期瓶颈还是GPU产能，包括台积电产能，CoWos（晶圆基板上芯片）和HBM（一款新型的CPU/GPU内存芯片）这些。

**腾讯新闻《潜望》：** 拆开说，训练一个GPT-3.5或GPT-4水平的模型，需要消耗多大算力和多少能源？

**李广密：** 三峡单日最大发电量和上海日均用电量差不多，都在5亿度左右，美国整个Texas德州是10亿度多一些。

假设GPT-3.5使用500张H100训练15天，大概需要25万度电，也就是三峡产电量或上海的用电量一天的0.05%左右，德州的0.02%。

假设GPT-4使用8000张H100训练100天，大概需要2600万度电，需要三峡或上海一天的5%左右，德州的2%。

假设GPT-5使用3.2万张H100训练100天，大概需要1.1亿度电，需要三峡或上海一天的20%左右，德州的8-10%。

**你要算成本的话，每张H100租用最低3-4美元/小时，大客户能再便宜点。**

**腾讯新闻《潜望》：** 训练到GPT-4水平，需要多少钱？

**李广密：**
一个GPT-4现在最低也要8000张H100有效算力，接近一个万卡集群。**你要是买卡，每张H100售价3万美金，再加上周边设备，3亿美金是少不了的。**

当然你也可以租。**如果是租H100 ，一年如果折扣比较好，1万多美金一张卡，就是差不多1亿到2亿美元。**

但今天的万卡集群中国比较少，万卡集群很难，每个卡都要连起来。网络拓扑结构很复杂，不是说一层网络，是三层网络。

**腾讯新闻《潜望》：** 算力从千卡集群到万卡集群再到现在的三万卡集群中心，造价成本是多少？难度有多大？

**李广密：**
每张H100售价3万美金，加上周边设备差不多4万美金，8000卡就意味3亿多美金，3.2万卡集群意味12-13亿美金。明年可能标配是10万张卡，就是差不多40-50亿美金。

最难的还是资源越来越集中收敛，能建大集群的客户很少，会收敛到极少的4-5家客户——微软，Meta，AWS；微软包含OpenAl；Google有自己的TPU，它可以很大集群；xAI可能也是一个。

影响难度的因素是，要找到适合数据中心的土地，稳定且便宜的电，之后是数据中心的互联通信、降温冷却、运维稳定可靠。还是回到那个问题，物理世界比数字世界改造要慢。

**腾讯新闻《潜望》：** 大基建现在有哪些公司在投资？进展如何？

**李广密：** 就看英伟达GPU出货量+TPU出货量，或者计算台积电产能。Meta和微软应该买走超过1/3 GPU的数量。

美股AI相关最大的几个生意：第一波最受益的是芯片，芯片里最受益的是英伟达和台积电；第二波是广告平台Meta和Google（广告匹配效率提升）；第三波云厂商，微软、AWS，因为芯片和模型都要跑在云厂商上，企业客户继续上云需求很强，云厂商未来每年很长时间保持年化15%复合增长都有可能；最后是两个终端Apple和Tesla——这些都是大基建最重要的几个关键玩家。

**腾讯新闻《潜望》：** OpenAI在基建上，截至目前投入有多大？

**李广密：** 不知道具体，你就看微软累计投入给OpenAI
130亿美元，这个累计够买30-40万张卡。你再计算英伟达GPU出货量，每年400万片GPU，大概多少比例给到OpenAI。如果5%就是每年新增20万片，每张卡3万美金，加上周边设备和未来电费，5万美金，那就是要一年100亿美元硬件投入。这样算OpenAI钱不够，还得做更大规模的融资，每年几个billion（十亿美金）投入。

如果按摊销每一年，那融资不用那么着急，如果一张H100每年起码1-1.5万美元租用费，最低折扣的话。

**腾讯新闻《潜望》：** 这些大基建的成本有可能分摊出去吗？必须要是模型公司自己承担吗？比如政府。

**李广密：**
有可能。未来有可能随着“主权AI”概念更深入，政府投资一家或多家模型公司是有可能的，而且大比例投资。你看欧洲有Mistral，我不知道欧洲是不是独立或半独立市场，如果欧洲的资源怼到Mistral，有可能它就得拿政府的钱了。

**腾讯新闻《潜望》：** 你预计AGI基建的时间表是怎样的？达到什么程度意味着大基建完成？

**李广密：**
时间表拉长了，主要是去年太兴奋觉得2-3年内实现AGI。现在预期更长，所以叫马拉松，至少3-5年或5-10年。得动态看，也看每个人对AGI的定义不一样。

去年预期是23年底就能看到GPT-5，能力可以超过一半同事，预期太高。去年这时候OpenAI先后发布了ChatGPT、GPT-3.5、GPT-4，大家觉得节奏快，这些模型都是之前OpenAI多年积累，提前训练好的，只是去年同时发出来。**但过去一年没有出现大幅超越GPT-4的模型。**

**训练很大的模型是很难的，不仅是数字世界问题，很多是物理硬件问题——比如实际H100规模化到货都是23年Q4，数据中心建设也都要3-6个月，还要把利用率提上去。**

人的预期可以飞上天，比特驱动的数字世界可以迭代很快，但原子主导的物理世界跟不上——就像你有意志力和体力跑马拉松，膝盖一个小环节出问题就跑不下去。膝盖问题可能不只是膝盖问题，是肌肉问题，而肌肉问题可能是训练方式问题。

大基建看不到结束那天。过去几十年半导体是最伟大发明，摩尔定律还在以新方式继续。

**腾讯新闻《潜望》：** 大基建周期之中，预期全球投入花多少钱？泡沫有多大？

**李广密：** 2024年GPU大概400万片产能，2025年600多万片GPU，未来每年复合增速不低于30%。三四年后，AI
GPU应该是3000-4000亿美元产业规模，这里还不包括TPU和其他未来的ASIC芯片。

AGI刚开始，长期看不算泡沫，把钱交给最厉害的科学家探索发现，有时一个新发现是能带来很大经济价值甚至社会价值的突破。

计算迭代停不下来，比如单颗芯片现在的摩尔定律还在提，依然没停下来，但进步速度变慢了。现在老黄又在提整个数据中心的摩尔定律，它通过互联，把整个数据中心变成一个大芯片，用这种方式继续。还有一种，未来还可以跨数据中心，能不能效率更高？这是停不下来了。如果你非要说一个时间，10-20年是一个大基建周期。

**腾讯新闻《潜望》：** 中国AGI大基建和美国AGI大基建，两边叙事差异是什么？

**李广密：**
美国历史上有大航海精神发现，包括开垦美洲大陆、曼哈顿计划造原子弹、登月、90年代克林顿网络都属于大基建，是面对不确定性的乐观、勇于冒险精神。美国资本和退出都很富足，富得早，有足够多的资本来做fundamental从0到1的试错发现。历史上很多从0到1的东西是美国搞出来，不管硅谷的芯片、计算机、互联网，波士顿的制药，他们文化里有重投入的传统，相信科学。

**不过硅谷VC很不争气，近乎全线miss大模型投资，他们好像对大模型的理解也很浅，全是巨头支持。中国VC更争气有出息吧，还支持了几家大模型公司从0到1发展起来。**

从Power Law（幂次定律）角度，硅谷主流的VC文化也不喜欢大模型这种“基建”型公司，SpaceX、Tesla几乎没啥硅谷VC参与。甚至在
LLM/AGI之前，机器人也属于很边缘的赛道，而现在是硅谷最火的赛道。硅谷VC喜欢花小钱办大事，这次不一样了。可能整个硅谷VC要交学费，价值沉淀大头会在基础大模型。

中国是解决问题的能力很强，提出新问题少，0-1很少，1-100很强。今天中国还在追GPT-4叙事，以及追谁是第一名。**目前中国大模型的技术辨识度不高，差异不大，大家过了3.5水平，但3.5到4的跨度是不小的。**

**腾讯新闻《潜望》：** 美国VC喜欢花小钱办大事，这不就是VC的本质吗？以小博大。

**李广密：** VC最应该是小钱办大事，但也有需要大钱的时候。

**腾讯新闻《潜望》：** 怎么看这次中国VC更争气这件事，他们为什么愿意大手笔支持大基建？

**李广密：** 因为美国有对标（笑）——中国VC都还是喜欢投有对标的东西，我们擅长解题。

**腾讯新闻《潜望》：** 为什么马斯克提能源问题？能源转化效率可量化吗？

**李广密：** AGI本质是：**电+芯片=产出智能，**
主要是今天怎么对智能定价？就像开车一脚油从A走到B，可以计算单位里程能耗，今天对智能没办法定价。我也好奇未来怎么定价。现在都是20美元/月，未来能不能有value
based定价机制。

**腾讯新闻《潜望》：** 在技术上、基建投入上，模型公司如果想跨越生死线，有一个基本标准吗？

**李广密：** 技术上：今年内超越GPT-4，背后是一支很优秀的团队，参考马斯克xAI。

二三线和国内模型公司：超越最好的开源模型，不然模型商业价值很小。

算力上：今年内万张卡集群，而且要能用起来，能做好的公司很少。**你就看未来12个月能不能有10万张H100的集群，这大概是三五十亿美元，这是明年第一梯队模型的标配。**

计算的竞争就是很残酷的，未来可能更残酷，每个时间阶段都会有模型公司持续的出局。

04 谈Scaling Law：微软和OpenAI的关系也挺复杂的

**腾讯新闻《潜望》：** 今天看，Scaling Law是加速增长，线性增长，还是放平缓了？

**李广密：** 从细节来看：GPT-4公开的是1.8T参数，MoE架构，大概13T训练数据，2.5万张A100训练100天。

外界都在猜测GPT下一代模型能scale
up多少倍？我们就假设如果是3倍参数，3倍多数据，那就是9倍compute资源。你看老黄公布了3.2万张H100集群，加上一些优化效率提升，是差不多match的。你要说10倍参数提升和10倍数据提升，那就是100倍compute资源提升，很明显GPU算力集群不够用，这里受限是物理机器瓶颈。

今天增加数据可能比增加参数的ROI要高，好像**高质量数据永远不嫌多。**
之前都说文本数据用差不多了，通过改写和合成能再扩大小几倍。今天真让你拿来10倍100T高质量数据好像有点难。可能没有人能拿出来。

另外，怎么把多模态数据和文本数据一起训练也挺难，是research问题，因为很容易伤害原来的模型。

现在对Scaling Law一个判断是，训练GPT-5数据够用，但GPT-6可能需要一些突破。未来1-2年Scaling
Law没问题。如果非说一个结论——Scaling Law
起码没减速；如果说变慢了，那就是算力和数据没怼够。GPT-3.5走到GPT-4大概多了20-30倍算力，GPT-4走向下一代还没怼够20-30倍有效算力。只要有有效算力和更多数据，一定有新东西出现。

这会影响到整个算力市场，围绕芯片、数据中心、互联。**接下来两年除了research问题，OpenAI、微软以及其他所有竞争对手，有50%甚至更多精力都会花在如何解决算力和互联的问题。**

这不光是一场research lab关于research的竞争，而是一场巨头博弈，research lab
和巨头互相leverage（影响、杠杆），对人才、用户、算力、policy、舆论、股价等资源多方争夺，互相角力的竞争——你看微软今年的动作，又投资Mistral，又投资Inflection，又自己招人在训大模型——它和OpenAI关系也挺复杂的。

**腾讯新闻《潜望》：** 评价一下微软这一系列动作。

**李广密：** 站住最稳的位置。

**腾讯新闻《潜望》：** Scaling Law走下去会遇到哪些瓶颈？能走多远？

**李广密：** 就看两个关键要素：第一，Data；第二，GPU。

电力不是research问题，是通过投入能解决的。反正Scaling
Law这个问题的结论是受限物理计算瓶颈，所以Sam提出筹集7万亿美金和造芯片是有道理的。

另外，效率很重要，一个是compute efficiency，一个是data
efficiency。这里有趣的就是衡量大家的效率，同样训练一个GPT-3.5能力水平的模型，需要多少张GPU？多少训练数据？这个训练效率可能是数量级差别——有人几千张，有人几百张就够，range很大。最后，AGI本质还是拼的用“能源+芯片”产出智能的效率。

最后从架构上，Agent能不能最终完成有经济价值的复杂任务，next
token到底能不能解决长期规划的问题，这是接下来值得关注的。如果不能，scaling下去意义不大。

**腾讯新闻《潜望》：** 模型会无限变大吗？

**李广密：** 我觉得会无限变大，参数大10倍甚至100倍，数据大10倍、100倍甚至1000倍。

训练大模型是为了探索能力边界，是科学发现问题，但大家都会训练更小的模型满足商用，成本很低。GPT-3.5也验证了这件事，我可以用训练SOTA大模型百分之一到十分之一的资源训练一个更efficient模型，能力上也能覆盖60-70%
query（查询），不见得明显比SOTA差太多，但成本低一到两个数量级。今天从头训练一个GPT-3.5水平模型应该不用太多卡。

**科普一个基本公式：训练量多大=参数量x训练token量x6**

number of parameters x tokens to train x 6 =number of GPU x FLOPS per GPU per
second x Time x utilization

举例，GPT-4：1.8 trillion 参数 x 13 trillion token x 6 = 25,000 GPU x 19.5
TFLOPs（19.5 万亿次） x 60s x 60mins x 24h x 100days x
利用率（利用率能到50%属于比较好的，最强的能到60%-70%）

**腾讯新闻《潜望》：** Scaling Law一定能通向AGI吗？

**李广密：** 这是最大概率的一条路线，我们没找到除了这条路以外的其他路径。在没有证伪之前要怼更多资源去验证。

**腾讯新闻《潜望》：** 你认可朱啸虎的观点吗？他说，AGI
5到10年内是看不见的——“可控核聚变实现前，我不太相信地球有足够的算力能够实现真正的AGI。帮人类降低90%的工作可能未来3到5年可以实现，但最后10%需要天量的算力和能耗，这也是为什么Sam
Altman想融天量的资金！”

**李广密：**
大部分观点是认可的，VC喜欢小钱办大事。回头看微软第一台计算机做出来的时候，盖茨也很难相信内存能从那时候的多少K到现在的多少GB。我们还是相信摩尔定律，以及模型的计算效率会提升，推理效率也会大幅提升，同时硬件的memory（存储）、模型本身的context
window（上下文窗口）也能提升很多。这些都提升上去后，人真的可以把自己所有的历史都当成context去运行。即使在这个过程中模型也还是会解锁很多新技能。

朱啸虎提到帮人类降低90%工作，这个经济价值挺高，3-5年如果实现，这个观点很乐观了。

我同意能量量级需要升级的观点，很多数据中心建在核电站旁边，AWS最近收购了一个美国最大核电站旁边的数据中心。

我对AGI理解的关键词是“渐进式解锁”，不是一蹴而就。今天Tesla
FSD（高级自动驾驶辅助系统）的安全性已经超过平均司机了，计算机视觉识别人脸和做广告商品识别推荐效率也比人高。我对5-10年内看见AGI充满信心，相信科学会有突破，相信这批全球最聪明厉害的科学家，这和曼哈顿计划、登月计划、克林顿网络大基建很像。

**腾讯新闻《潜望》：** 朱啸虎还有一个观点是，GPT-5以后大模型的技术曲线基本会放缓下来。

**李广密：**
技术发展不是线性的，可能平台期2年，再跳变跃升一次，有一个更大主声浪。几十万张卡训练AGI，可能比登月对人类的经济价值更大。**我认为，模型作为新的平台，确定性已经很高了。**

05 预测OpenAI：挑软柿子嘛，就打Google

**腾讯新闻《潜望》：** 你说最近几个月对OpenAI有了新认知，能不能展开讲讲？

**李广密：我一开始觉得AGI公司不应该太激进做产品，OpenAI现在也很激进地做产品。**
你一边做科学发现，一边做商业化，要把这些发现的价值接住。这意味OpenAI会和一部分创业公司抢市场，当然肯定也有很多垂直行业它做不了。

如果我是Sam，AGI如果10年，每年都需要几个billion甚至10个billion投入，我需要商业化，需要有持续健康的现金流支持AGI。纯靠融资是很难融到那么多钱，你也不能只依赖微软——健康地走向AGI很关键。

**腾讯新闻《潜望》：** 在你看来，有什么是OpenAI这家公司会做的，什么是他们不会做的？

**李广密：** 他们AGI和超级应用都想做。To B企业客户对OpenAI难一些，企业客户是信任生意。微软在企业客户信任太深，To
B大部分价值会被微软吃掉。OpenAI就做到模型领先和To C产品能有流量入口。

OpenAI垂直领域不一定会做，否则战线太宽，但是垂直领域的数据它可能会持续加上去，要把一些use
case给做得更好，让创业公司用它的模型服务最后一公里的客户。法律/教育/金融估计不一定。机器人不好说，它以前做过，觉得太慢，过去一年投了3家机器人公司，今天在扶持。如果机会到了，它有可能自己做机器人，因为机器人从数字世界走向物理世界，是AGI比较关键的。

如果是我，我会先把ChatGPT从5000万DAU做到3个亿，有可能这会对Google产生fundamental影响。你看ChatGPT现在不到1000万付费用户，如果我做到3000万付费用户，是每年60亿美金订阅收入，那就可以健康支撑AGI每年的投入。

就拿mega7放在竞争视角对比，**OpenAI很难和微软竞争To
B企业市场，短期也很难和英伟达竞争芯片市场，更难和Apple竞争消费终端市场，大概率Google是个软柿子，可以去抢信息检索的市场，这比较make
sense。**

（接下来OpenAI）会做更强模型，ChatGPT活跃用户规模考虑怎么再翻个三五倍甚至更多？挑软柿子嘛，就打Google——Google的市场太肥了。

**腾讯新闻《潜望》：** OpenAI凭什么估值1000亿美元？

**李广密：** 你把它看成微软的AI部门，微软因此涨了1T到1.5T。你看Tesla AI都值2000-3000亿美元。

**腾讯新闻《潜望》：** 怎么看Sam 提出的7万亿美金芯片计划？中东在全球大模型战局扮演什么角色？

**李广密：** 微软和OpenAI应该做ASIC芯片，或者起码具备这个能力。如果AGI是长跑，今天应该做准备。**会不会有一个新的芯片联盟出现？**
主要是英伟达卖太贵了。肯定不会有7万亿美金这么多钱，但需要不少钱，中东是潜在最大出资方。

**腾讯新闻《潜望》：** 你对GPT-5的预测是什么？

**李广密：** 夏天or下半年推出？也是猜测。看能不能涌现新能力？能不能解决复杂任务？Agent能不能落地？

**腾讯新闻《潜望》：** 现在2024年刚刚过完一个季度，你对接下来三个季度的AGI演进有哪些预测？

**李广密：** 有很多期待。

1.GPT下一代 SOTA模型scale up幅度多大，是观测Scaling Law work的最重要指标。以及，下一代模型能涌现哪些新能力？

2.OpenAI这家公司能不能做好产品？如果他们做信息检索，会不会对Google产生fundamental影响？

3.多模态进一步怎么样？可能对自动驾驶和机器人影响最大的。

4.如果今年是收敛之年，年底收敛到几家模型？

5.会不会有GPT-4水平的开源模型出来？

6.单一模态的创业公司会怎样？单模态公司如果只做模型是很危险的，但如果把产品链做得很好好像也有壁垒。

06 推演进一步结盟：期待Apple、英伟达、Meta如何做选择

**腾讯新闻《潜望》：** 现在美国大模型赛场上是集团军作战，接下来会有更多结盟吗？

**李广密：** 微软和OpenAI联盟目前是稳定的；AWS和Anthropic继续互相更深入绑定，AWS销售已经全线卖Claude
3了；Google自成一体；马斯克xAI长期不排除并入Tesla或Twitter的可能性；欧洲Mistral必须有个大腿支持，他们之前效率很高，2k
H100做到现在水平，未来1年至少需要10-30亿美金融资，万张卡集群，不然后面也会掉队。

比较期待Apple、英伟达、Meta如何做选择。

OpenAI买一家芯片公司，形成新的芯片联盟？

Apple发了一些小模型，但Apple短期追上GPT-4水平比较难。但手机还是最重要的入口和习惯，Apple的位置长期是比较稳的。Apple训练很大的模型，今天看追不上OpenAI，但他们肯定是云和端结合，调用多个模型也不是没可能。

**腾讯新闻《潜望》：** 你怎么看他们放弃了造车？

**李广密：** 美国制造业不太行，也没等到自动驾驶来。

很多人都在提AI
PC、AI手机。**但真的把一个大模型变成小模型装到端上，很难，因为现在1B模型做不了太多，但手机跑1B模型能耗要求比较高，这又回到那个物理问题，物理迭代比较慢。**
如果你手机放一个比较大的模型，内存也要很大，电池也要很大，这个手机迭代比较慢。包括Tesla
FSD在端上，因为它要latency（延迟）要求很高，也不能太大。

**腾讯新闻《潜望》：** 英伟达会绑定模型公司吗？

**李广密：** 有很大可能。如果我是英伟达，我不希望OpenAI一家独大，多扶持三五家可以更多卖卡。如果OpenAI一家独大，英伟达PE又得下来一截。

**腾讯新闻《潜望》：** 怎么看这几个月中国大模型公司和巨头的结盟动态？（阿里有大动作，投了所有中国大模型创业公司。）

**李广密：**
云可能是比芯片和模型大个3-5倍的生意，最后更多生产流程继续上云，但这里价值链分配比例会发生变化，所以阿里云必须要投入。期待阿里新CEO吴妈（吴泳铭）能成为微软CEO
Satya一样的人，让阿里大象起舞。

**腾讯新闻《潜望》：** 为什么阿里是同时分散投到多家而不是全部重注到一家模型公司？

**李广密：**
（国内模型公司）技术辨识度不够高。另外我的投资可以绑定算力消耗，最后钱都还是要回来的。如果我投出去一块钱，训练又花一块钱，我的收入又多了一块钱，那我的市值可能又是10块钱。

07 谈 Sam、黄仁勋和马斯克：我一直没搞懂Sam怎么有那么多钱？他也没大的退出啊…

**腾讯新闻《潜望》：** 最后，我们聊几个硅谷的重要人物吧，你怎么评价Sam Altman？

**李广密：**
Sam有很多争议，但在OpenAI成名前，他坚持做这家公司七年，在很多人都不相信LLM能成的情况下，这点非常值得尊敬。相比起来，马斯克是中间放弃，现在回过头来觉得这个东西好。

OpenAI在同时做地球上两件最难的事：AGI + Killer
App，两种culture平衡很难。Sam有勇气去探索一些别人没有探索过的东西，比如复杂的公司架构，比如敢于提出硅谷需要一些投入资金和时间成本巨大的项目。也确实在这上面吃了亏。

Sam在采访里让人印象比较深的一个点是，他对GPT-4的形容是sucks（很糟糕），他表现出对产品和模型的要求很高，认为GPT-4离想要达到的目标还非常远，明年看GPT-4就是小模型或者很笨，不应该觉得现在的产品已经amazing了。我比较认可Sam的一句话，科技进步创造经济价值增长，所以要提高科学发现的速度。

**Sam个人好像投资很多，感觉得有几个billion，我一直没搞懂他怎么有那么多钱？他之前也没大的退出啊……**

**腾讯新闻《潜望》：** 怎么看马斯克和OpenAI之间的官司？

**李广密：** xAI打不过OpenAI？OpenAI变成了最靓的仔，散户的钱在从Tesla流出，马斯克得维护最靓的仔的形象，Tesla才有高PE估值。

马斯克肯定也不爽吧，毕竟这个idea是他发起的，结果今天和自己无关，没捞到什么好处。不过OpenAI后来变成一个商业盈利组织，和之前非盈利的初心是有些冲突的，但纯粹的非盈利组织很难获取太多资源训练大的模型，Sam找到微软合作也没毛病。

**腾讯新闻《潜望》：** 怎么看Sam和黄仁勋在硅谷的地位，谁更高？

**李广密：** 短期还是老黄地位高，英伟达是人类基石公司，没有老黄不行，没有Sam
AGI也许也可以实现。但长期来说OpenAI价值也许更大，Sam成为智能的新教主，前提是芯片不受限英伟达。未来商业社会多两层收税的公司，英伟达收芯片算力税，OpenAI收模型智能税。

**腾讯新闻《潜望》：** AGI时代，现在美国VC都在投什么？他们今年更激进还是更保守了？

**李广密：硅谷投资的主题已经变成Coding、Agent和机器人三大件。**
不过这三大件我有很大怀疑，Coding一定是大模型公司和微软的核心射程内，核心能力都来自模型公司，不确定上层优化价值有多大。

基础模型公司都会很激进做Agent，因为这个附加值高，模型即能力，模型即应用，模型即Agent，整个价值沉淀我觉得还是基础模型本身。

Cognition和Magic没有收入，就有 20 亿美元估值，说明了对Coding和Agent的hype（炒作）比较高。

机器人是几乎所有researcher目前创业的首选，因为容易讲故事和融资，觉得未来会有embodied
OpenAI。机器人反正最近OpenAI投了几家，也许是好的timing，bet对一个很强的团队，核心是能持续融资和吸引最顶尖的人才。

投资节奏属于正常，但估值都很贵。AI好的确定性高的deal并不多，今天还是GPU和LLM基建最重要。

**腾讯新闻《潜望》：** 为什么我们作为碳基智能，一直在追求硅基智能上这么热衷？

**李广密：**
这个很有意思，最终AGI期待的一个结果是，不管是Agent还是其他形态，能够把所有的计算资源和能源都用得有意义，思考和解决人类没想过的问题。

碳基肉身有局限，吞吐量有限，记忆长度短，读不了DNA/RNA，人也不能规模化复制，碳基和硅基是很好的互补。

**未来十年硅基的AGI和地缘博弈，这两个可能是交叉的。**


# 腾讯混元大模型升级：新增“文生图”，内部已经在用混元大模型写代码

# 腾讯混元大模型升级：新增“文生图”，内部已经在用混元大模型写代码

腾讯科技讯
10月26日，腾讯宣布，腾讯混元大模型迎来全新升级：首次正式对外开放“文生图”功能，展示了其在图像自动生成领域的领先能力；中文能力升级，能力整体超过GPT3.5；代码能力大幅提升20%，达到业界领先水平。

腾讯自研的面向垂直领域的7B和13B模型也首次亮相，同等效果下仅需较少的tokens，训练效率更高。模型实测中英文效果整体优于国内外开源模型，能够以更高的性价比和效率支持应用落地，满足各种垂直场景和业务需求，助力腾讯全面拥抱大模型。

目前，超过180个腾讯内部业务已接入腾讯混元，包括腾讯会议、腾讯文档、企业微信、腾讯广告和微信搜一搜等。最近，QQ浏览器还基于腾讯混元推出了“PDF阅读助手”，具备智能摘要、智能问答和多轮提问等功能。

另外，已有来自零售、教育、金融、医疗、传媒、交通、政务等多个行业的客户，通过腾讯云调用腾讯混元大模型API，应用领域涉及智能问答、内容创作、数据分析、代码助手等多个场景。今年9月首批通过备案后，腾讯混元大模型也已经面向C端用户陆续开放体验，用户通过小程序或网页端，就能与腾讯混元对话。

据了解，腾讯掌握从模型算法到机器学习框架再到AI基础设施的全链路自研技术，这为大模型的快速迭代提供了有利条件。自首次公开亮相以来，腾讯混元大模型进入了加速升级的轨道。在自研算法的支持下，模型稳定性和可靠性稳步提升。

从2021年开始，腾讯先后推出千亿和万亿参数的NLP稀疏大模型，打破CLUE三大榜单纪录，实现在中文理解能力上的新突破。2023年9月混元大模型的亮相，代表腾讯在大模型理解和生成通路上的融合打通。随着文生图功能的出现，腾讯混元大模型加入了对图像的处理能力，模态进一步丰富。

**一、针对文生图三个技术难点，提出了一系列原创算法**

文生图是AIGC领域的核心技术之一，也是体现通用大模型能力的试金石，对模型算法、训练平台、算力设施都有较高的要求。

腾讯最早在广告场景进行AI自动生成图像的探索，据介绍，相比其他大模型，腾讯混元的文生图应用，在人像真实感、场景真实感上有比较明显的优势，例如在在业界公认难度较高的人脸画像生成上。

输入提示词“生成可爱的亚洲 4 岁女孩穿着棉质连衣裙，大眼睛，古代中国，摄影风格，汉服”，腾讯混元大模型生成如下：

![](https://inews.gtimg.com/news_bt/OYWznO9mQfbtpU8tKTgon91-KARLITH7jwNDCSfptEk0sAA/1000)

可以看到，腾讯混元大模型可以很好地理解提示词中提到的“棉质连衣裙”、“汉服”等内容，同时在风格上，也通过建筑和风景等衬托，很好的展示了“古代中国”的风格要求。

同时，混元大模型在中国风景、动漫游戏等场景等生成上都有较好的表现。例如，输入提示词“
一个城市CBD办公楼，现代化设计，高层建筑，玻璃幕墙，近景拍摄，摄影风格，摄影照片”，腾讯混元大模型生成的图片如下：

![](https://inews.gtimg.com/news_bt/OVReVaXjaDo8YSWsl2ATvleJaNONcWSF3NfI2ic7i3NN8AA/1000)

更简单一些，输入提示词“轻舟已过万重山，水墨画风格”就可以得到下面的图片：

![](https://inews.gtimg.com/news_bt/OwPgvzqHJEvJyIZREzlpi4YnkDOlg63chqv7g7OgeAawkAA/1000)

**大模型文生图的难点体现在对提示词的语义理解、生成内容的合理性以及生成图片的效果**
。针对这三个技术难点，腾讯进行了专项的技术研究，提出了一系列原创算法，来保证生成图片的可用性和画质。

首先， **在语义理解方面**
，腾讯混元采用了中英文双语细粒度的模型。模型同时建模中英文实现双语理解，并通过优化算法提升了模型对细节的感知能力与生成效果，有效避免多文化差异下的理解错误。

**在内容合理性方面**
，AI生成人体结构和手部经常容易变形。混元文生图通过增强算法模型的图像二维空间位置感知能力，并将人体骨架和人手结构等先验信息引入到生成过程中，让生成的图像结构更合理，减少错误率。

**在画面质感方面**
，混元文生图基于多模型融合的方法，提升生成质感。经过模型算法的优化之后，混元文生图的人像模型，包含发丝、皱纹等细节的效果提升了30%，场景模型，包含草木、波纹等细节的效果提升了25%。

![](https://inews.gtimg.com/news_bt/O6e8-sphi9u2C5vUxaawTXFDcL0vSx_JbJt4IIK7yquLMAA/1000)

prompt：生成一幅照片：桂林漓江的山水，江上有一艘小船

腾讯混元文生图能力，目前已经被用于素材创作、商品合成、游戏出图等多项业务中，此外在广告业务下的多轮测评中，腾讯混元文生图的案例优秀率和广告主采纳率分别达到86%和26%，均高于同类模型。

**腾讯内部已经在用混元大模型“写”代码**

过去一个月，腾讯混元大模型不仅各项能力均有升级，代码、数学能力也大幅提升。经过对32种主流语言代码文件、各类计算机书籍和博客的学习增训，腾讯混元代码处理水平提升超过20%，代码处理效果胜出ChatGPT
6.34%，在HumanEval公开测试集指标上全面超过Starcoder、Codellama等业界头部开源代码大模型。

例如，输入简单的指令“帮我用前端语言实现一个贪吃蛇”，腾讯混元便能自动生成可运行的代码，快速制作出一个贪吃蛇小游戏。支持Python、C++、Java、Javascript等多种语言的指令生成，比如输入“用Python画红色的心形线”，混元会提供代码库选择、安装命令、绘制代码等具体操作步骤的指引。

![](https://inews.gtimg.com/news_bt/O6WBMiqgn2lQbGjKPLydTxboLLH5SK7LVuuEvQEXuJB6kAA/1000)
_Prompt：用Python画红色的心形线_

腾讯内部目前已经有多个开发平台接入了腾讯混元大模型，工程师们可以使用腾讯混元来进行代码生成、代码补全、代码漏洞检测和修复、表格数据处理、数据库查询等工作。

比如，在IDE编程场景中，腾讯工蜂Copilot通过接入混元大模型，可根据注释生成对应代码，或基于上下文智能补全代码，大大提高了编程效率。混元大模型还可以帮助用户进行代码漏洞检测和修复，保障软件开发过程中的安全性。

腾讯混元大模型持续升级背后，离不开腾讯自研一站式机器学习平台Angel的支撑。自研AngelPTM训练框架可提供高效的分布式训练解决方案，具备业界领先的内存利用率和训练吞吐效率，训练速度相比业界主流框架提升1
倍；自研AngelHCF训练框架，具备从蒸馏、微调、压缩到模型加速的完整能力，支持多种模型并行，保证模型的最小化部署及最大化吞吐，推理速度相比业界主流框架FasterTransformer快1.3倍。

大模型多模态交互能力被认为是通往通用人工智能的必由之路，也是不断扩充大模型能力象限的一个重要方向。据介绍，腾讯混元大模型正在不断强化图片、视频、音频等各类模态的处理能力，相关成果也将很快面向外界推出。

